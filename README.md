AI Orchestrator
A simple AI-powered task orchestrator that leverages a Large Language Model (LLM) to parse user requests and automatically execute relevant containerized tasks like data cleaning and sentiment analysis.

âœ¨ Features
ğŸ”— LLM Integration â€“ Uses Groqâ€™s llama3-70b-8192 model to intelligently parse user intent.

ğŸ³ Containerized Services â€“ Clean and modular tasks using Docker containers.

ğŸ§¹ Data Cleaner â€“ Removes empty rows from CSV data using pandas.

ğŸ’¬ Sentiment Analyzer â€“ Detects sentiment in text using TextBlob.

ğŸ§° CLI Interface â€“ Interact with the orchestrator from the command line.

ğŸ§© Docker Compose â€“ Handles service orchestration with ease.

ğŸ“œ Logged Output â€“ Detailed logs for every step of the execution process.

ğŸ“ Project Structure

ai-orchestrator/
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ main.py                # Main orchestrator logic
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ data_cleaner/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ clean.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ sentiment_analyzer/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ analyze.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml         # Orchestration config
â”œâ”€â”€ README.md                  # This file


Features Implemented
LLM Integration:

Uses Groq's Llama3-70b model to interpret user requests

Simple prompt engineering to map requests to containerized tasks

JSON response parsing with error handling

Containerized Services:

Data cleaning service (removes empty rows from CSV)

Sentiment analysis service (TextBlob-based)

Each service in its own Docker container

Orchestrator:

Coordinates the workflow

Handles user input

Manages container execution

Collects and presents results

Error Handling:

Basic error handling for LLM responses

Error handling in containerized services

âš™ï¸ Setup Instructions
1. Install Prerequisites

Python 3.9 or higher
Docker Desktop
VS Code (optional)
Groq API Key (free signup)

2. Set Up the Project
Clone or create a folder with the structure above.

3. Install Python Dependencies

cd ai-orchestrator/orchestrator
pip install -r requirements.txt

4. Set Your Groq API Key
Windows:
set GROQ_API_KEY=your_api_key_here

macOS/Linux:
export GROQ_API_KEY=your_api_key_here

5. Build Docker Containers
From the root directory:
docker-compose build

6. Run the Orchestrator
Navigate to the orchestrator directory:

cd orchestrator
python main.py
You'll be prompted to input:

A request (e.g., "Clean this dataset")

Corresponding data (e.g., "name,age\nAlice,25\n,,30\nBob,28")

The orchestrator will:

Ask the LLM to decide the appropriate tasks.

Run the relevant Docker containers.

Show the final output.

ğŸ§  Example Usage

Request: Clean this dataset  
Data: name,age\nAlice,25\n,,30\nBob,28

Output:
Cleaned CSV:
name,age
Alice,25
Bob,28

Input:
Request: Analyze sentiment in this text  
Data: I love this product!

Output:
Sentiment: Positive

ğŸ§­ Architecture Overview
The orchestrator follows a modular, containerized architecture:

main.py takes user input and asks the Groq LLM what needs to be done.

Based on the response, relevant containers are run via Docker Compose.

Each container performs a task:

CSV cleanup via pandas

Sentiment analysis via TextBlob

Results are collected and returned to the user in CLI.

This decoupled design allows easy scaling â€“ just add a new service folder and map it to a task.

ğŸ§ª Demo Video
A screen recording (provided separately) demonstrates:

Cleaning a CSV dataset

Analyzing text sentiment

Orchestrator's interaction with containers

ğŸ§¾ Assumptions
Inputs are raw text or CSV strings.

Groq API returns a valid JSON task list.

Docker Desktop is running during execution.

ğŸ“Œ Future Enhancements
Add services like:

ğŸ“„ Summarization

ğŸŒ Translation

ğŸ“Š Keyword extraction

Retry mechanism for failed containers

Web interface for non-technical users

Real-time progress bar in CLI

